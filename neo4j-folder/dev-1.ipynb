{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c901b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 12:39:53,287 - INFO - 703 tez verisi yüklendi\n",
      "2025-05-18 12:39:53,288 - INFO - Neo4j bağlantısı kuruldu\n",
      "2025-05-18 12:39:53,420 - INFO - Veritabanı temizlendi\n",
      "2025-05-18 12:39:53,499 - INFO - Constraint oluşturuldu: CREATE CONSTRAINT thesis_id IF NOT EXISTS FOR (t:Thesis) REQUIRE t.id IS UNIQUE\n",
      "2025-05-18 12:39:53,539 - INFO - Constraint oluşturuldu: CREATE CONSTRAINT stakeholder_name IF NOT EXISTS FOR (s:STAKEHOLDER) REQUIRE s.name IS UNIQUE\n",
      "2025-05-18 12:39:53,570 - INFO - Constraint oluşturuldu: CREATE CONSTRAINT problem_challenge_name IF NOT EXISTS FOR (p:PROBLEM_CHALLENGE) REQUIRE p.name IS UNIQUE\n",
      "2025-05-18 12:39:53,599 - INFO - Constraint oluşturuldu: CREATE CONSTRAINT solution_approach_name IF NOT EXISTS FOR (s:SOLUTION_APPROACH) REQUIRE s.name IS UNIQUE\n",
      "2025-05-18 12:39:53,630 - INFO - Constraint oluşturuldu: CREATE CONSTRAINT focus_area_theme_name IF NOT EXISTS FOR (f:FOCUS_AREA_THEME) REQUIRE f.name IS UNIQUE\n",
      "2025-05-18 12:39:53,634 - INFO - Entity frekansları hesaplanıyor...\n",
      "2025-05-18 12:39:53,643 - INFO - Toplam 3140 unique entity oluşturuluyor...\n",
      "2025-05-18 12:40:04,616 - INFO - Entity'ler oluşturuldu\n",
      "2025-05-18 12:40:04,616 - INFO - Tezler ve CONTAINS ilişkileri oluşturuluyor...\n",
      "2025-05-18 12:40:09,104 - INFO - İşlenen tez sayısı: 100/703\n",
      "2025-05-18 12:40:13,293 - INFO - İşlenen tez sayısı: 200/703\n",
      "2025-05-18 12:40:16,542 - INFO - İşlenen tez sayısı: 300/703\n",
      "2025-05-18 12:40:19,605 - INFO - İşlenen tez sayısı: 400/703\n",
      "2025-05-18 12:40:22,545 - INFO - İşlenen tez sayısı: 500/703\n",
      "2025-05-18 12:40:25,569 - INFO - İşlenen tez sayısı: 600/703\n",
      "2025-05-18 12:40:28,290 - INFO - İşlenen tez sayısı: 700/703\n",
      "2025-05-18 12:40:28,399 - INFO - Tezler ve CONTAINS ilişkileri tamamlandı\n",
      "2025-05-18 12:40:28,399 - INFO - Relation'lar hesaplanıyor ve oluşturuluyor...\n",
      "2025-05-18 12:40:33,239 - INFO - İşlenen relation sayısı: 500\n",
      "2025-05-18 12:40:36,422 - INFO - İşlenen relation sayısı: 1000\n",
      "2025-05-18 12:40:39,364 - INFO - İşlenen relation sayısı: 1500\n",
      "2025-05-18 12:40:42,484 - INFO - İşlenen relation sayısı: 2000\n",
      "2025-05-18 12:40:45,319 - INFO - İşlenen relation sayısı: 2500\n",
      "2025-05-18 12:40:47,957 - INFO - İşlenen relation sayısı: 3000\n",
      "2025-05-18 12:40:50,746 - INFO - İşlenen relation sayısı: 3500\n",
      "2025-05-18 12:40:53,443 - INFO - İşlenen relation sayısı: 4000\n",
      "2025-05-18 12:40:56,068 - INFO - İşlenen relation sayısı: 4500\n",
      "2025-05-18 12:40:58,711 - INFO - İşlenen relation sayısı: 5000\n",
      "2025-05-18 12:41:01,401 - INFO - İşlenen relation sayısı: 5500\n",
      "2025-05-18 12:41:04,060 - INFO - İşlenen relation sayısı: 6000\n",
      "2025-05-18 12:41:06,196 - INFO - Toplam 6430 unique relation oluşturuldu\n",
      "2025-05-18 12:41:06,196 - INFO - Veri aktarımı tamamlandı\n",
      "2025-05-18 12:41:06,198 - INFO - Veri aktarımı başarıyla tamamlandı\n",
      "2025-05-18 12:41:06,199 - INFO - Neo4j bağlantısı kapatıldı\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, List, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "# Loglama yapılandırması\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Neo4jImporter:\n",
    "    def __init__(self, uri: str, user: str, password: str):\n",
    "        \"\"\"Neo4j veritabanına bağlantı kurulumu\"\"\"\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        logger.info(\"Neo4j bağlantısı kuruldu\")\n",
    "        \n",
    "    def close(self):\n",
    "        \"\"\"Veritabanı bağlantısını kapatır\"\"\"\n",
    "        self.driver.close()\n",
    "        logger.info(\"Neo4j bağlantısı kapatıldı\")\n",
    "        \n",
    "    def create_constraints(self):\n",
    "        \"\"\"Indeksler ve kısıtlamalar oluşturur\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            constraints = [\n",
    "                \"CREATE CONSTRAINT thesis_id IF NOT EXISTS FOR (t:Thesis) REQUIRE t.id IS UNIQUE\",\n",
    "                \"CREATE CONSTRAINT stakeholder_name IF NOT EXISTS FOR (s:STAKEHOLDER) REQUIRE s.name IS UNIQUE\",\n",
    "                \"CREATE CONSTRAINT problem_challenge_name IF NOT EXISTS FOR (p:PROBLEM_CHALLENGE) REQUIRE p.name IS UNIQUE\",\n",
    "                \"CREATE CONSTRAINT solution_approach_name IF NOT EXISTS FOR (s:SOLUTION_APPROACH) REQUIRE s.name IS UNIQUE\",\n",
    "                \"CREATE CONSTRAINT focus_area_theme_name IF NOT EXISTS FOR (f:FOCUS_AREA_THEME) REQUIRE f.name IS UNIQUE\"\n",
    "            ]\n",
    "            \n",
    "            for constraint in constraints:\n",
    "                try:\n",
    "                    session.run(constraint)\n",
    "                    logger.info(f\"Constraint oluşturuldu: {constraint}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Constraint mevcut veya hata: {e}\")\n",
    "    \n",
    "    def clear_database(self):\n",
    "        \"\"\"Veritabanındaki tüm veri ve ilişkileri temizler\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            logger.info(\"Veritabanı temizlendi\")\n",
    "    \n",
    "    def bulk_import_optimized(self, data: List[Dict[str, Any]]):\n",
    "        \"\"\"Optimize edilmiş toplu veri import'u\n",
    "        \n",
    "        Strateji:\n",
    "        1. Önce tüm entity'leri ve frekanslarını hesapla\n",
    "        2. Entity'leri toplu olarak oluştur\n",
    "        3. Tezleri oluştur ve CONTAINS ilişkilerini toplu ekle\n",
    "        4. Relation'ları global olarak birleştir ve toplu ekle\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. ENTITY FREKANSLARINI HESAPLA\n",
    "        entity_data = defaultdict(lambda: {\n",
    "            'thesis_ids': set(), \n",
    "            'years': [],\n",
    "            'type': None\n",
    "        })\n",
    "        \n",
    "        logger.info(\"Entity frekansları hesaplanıyor...\")\n",
    "        for thesis in data:\n",
    "            thesis_id = thesis.get(\"thesis_id\", \"\")\n",
    "            year = thesis.get(\"year\", 0)\n",
    "            entities = thesis.get(\"entities\", {})\n",
    "            \n",
    "            for entity_type, entity_list in entities.items():\n",
    "                for entity_name in entity_list:\n",
    "                    key = (entity_type, entity_name)\n",
    "                    entity_data[key]['thesis_ids'].add(thesis_id)\n",
    "                    entity_data[key]['years'].append(year)\n",
    "                    entity_data[key]['type'] = entity_type\n",
    "        \n",
    "        # 2. ENTITY'LERİ TOPLU OLARAK OLUŞTUR\n",
    "        logger.info(f\"Toplam {len(entity_data)} unique entity oluşturuluyor...\")\n",
    "        with self.driver.session() as session:\n",
    "            for (entity_type, entity_name), data_dict in entity_data.items():\n",
    "                thesis_ids = list(data_dict['thesis_ids'])\n",
    "                years = data_dict['years']\n",
    "                \n",
    "                session.run(\n",
    "                    f\"\"\"\n",
    "                    MERGE (e:{entity_type} {{name: $name}})\n",
    "                    SET e.type = $type,\n",
    "                        e.frequency = $frequency,\n",
    "                        e.first_occurrence_year = $first_year,\n",
    "                        e.last_occurrence_year = $last_year,\n",
    "                        e.thesis_ids = $thesis_ids\n",
    "                    \"\"\",\n",
    "                    name=entity_name,\n",
    "                    type=entity_type,\n",
    "                    frequency=len(thesis_ids),\n",
    "                    first_year=min(years),\n",
    "                    last_year=max(years),\n",
    "                    thesis_ids=thesis_ids\n",
    "                )\n",
    "        \n",
    "        logger.info(\"Entity'ler oluşturuldu\")\n",
    "        \n",
    "        # 3. TEZLER VE CONTAINS İLİŞKİLERİNİ OLUŞTUR\n",
    "        logger.info(\"Tezler ve CONTAINS ilişkileri oluşturuluyor...\")\n",
    "        with self.driver.session() as session:\n",
    "            for i, thesis in enumerate(data):\n",
    "                thesis_id = thesis.get(\"thesis_id\", \"\")\n",
    "                year = thesis.get(\"year\", 0)\n",
    "                \n",
    "                # Tez oluştur\n",
    "                session.run(\n",
    "                    \"MERGE (t:Thesis {id: $id}) SET t.year = $year\",\n",
    "                    id=thesis_id, year=year\n",
    "                )\n",
    "                \n",
    "                # CONTAINS ilişkilerini toplu ekle\n",
    "                entities = thesis.get(\"entities\", {})\n",
    "                for entity_type, entity_list in entities.items():\n",
    "                    for entity_name in entity_list:\n",
    "                        session.run(\n",
    "                            f\"\"\"\n",
    "                            MATCH (t:Thesis {{id: $thesis_id}})\n",
    "                            MATCH (e:{entity_type} {{name: $entity_name}})\n",
    "                            MERGE (t)-[r:CONTAINS]->(e)\n",
    "                            SET r.year = $year\n",
    "                            \"\"\",\n",
    "                            thesis_id=thesis_id,\n",
    "                            entity_name=entity_name,\n",
    "                            year=year\n",
    "                        )\n",
    "                \n",
    "                if (i + 1) % 100 == 0:\n",
    "                    logger.info(f\"İşlenen tez sayısı: {i + 1}/{len(data)}\")\n",
    "        \n",
    "        logger.info(\"Tezler ve CONTAINS ilişkileri tamamlandı\")\n",
    "        \n",
    "        # 4. RELATION'LARI TOPLU OLARAK VE BİRLEŞTİREREK OLUŞTUR\n",
    "        logger.info(\"Relation'lar hesaplanıyor ve oluşturuluyor...\")\n",
    "        \n",
    "        # Tüm relation'ları topla ve birleştir\n",
    "        relation_data = defaultdict(lambda: {\n",
    "            'thesis_ids': set(),\n",
    "            'years': []\n",
    "        })\n",
    "        \n",
    "        for thesis in data:\n",
    "            thesis_id = thesis.get(\"thesis_id\", \"\")\n",
    "            year = thesis.get(\"year\", 0)\n",
    "            relations = thesis.get(\"relations\", [])\n",
    "            \n",
    "            for relation in relations:\n",
    "                source = relation.get(\"source\", \"\")\n",
    "                target = relation.get(\"target\", \"\")\n",
    "                relation_type = relation.get(\"relation\", \"\")\n",
    "                \n",
    "                if source and target and relation_type:\n",
    "                    # Normalize relation type (örn. ADRESSES -> ADDRESSES)\n",
    "                    if relation_type == \"ADRESSES\":\n",
    "                        relation_type = \"ADDRESSES\"\n",
    "                    elif relation_type == \"CAUSES\":\n",
    "                        continue  # Skip unknown relation types\n",
    "                    \n",
    "                    key = (source, target, relation_type)\n",
    "                    relation_data[key]['thesis_ids'].add(thesis_id)\n",
    "                    relation_data[key]['years'].append(year)\n",
    "        \n",
    "        # Relation'ları oluştur\n",
    "        with self.driver.session() as session:\n",
    "            relation_count = 0\n",
    "            for (source, target, relation_type), rel_data in relation_data.items():\n",
    "                thesis_ids = list(rel_data['thesis_ids'])\n",
    "                years = rel_data['years']\n",
    "                \n",
    "                session.run(\n",
    "                    f\"\"\"\n",
    "                    MATCH (source) WHERE source.name = $source\n",
    "                    MATCH (target) WHERE target.name = $target\n",
    "                    MERGE (source)-[r:{relation_type}]->(target)\n",
    "                    SET r.weight = $weight,\n",
    "                        r.first_occurrence_year = $first_year,\n",
    "                        r.last_occurrence_year = $last_year,\n",
    "                        r.thesis_ids = $thesis_ids\n",
    "                    \"\"\",\n",
    "                    source=source,\n",
    "                    target=target,\n",
    "                    weight=len(thesis_ids),\n",
    "                    first_year=min(years),\n",
    "                    last_year=max(years),\n",
    "                    thesis_ids=thesis_ids\n",
    "                )\n",
    "                \n",
    "                relation_count += 1\n",
    "                if relation_count % 500 == 0:\n",
    "                    logger.info(f\"İşlenen relation sayısı: {relation_count}\")\n",
    "        \n",
    "        logger.info(f\"Toplam {relation_count} unique relation oluşturuldu\")\n",
    "        logger.info(\"Veri aktarımı tamamlandı\")\n",
    "\n",
    "def load_json_data(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"JSON dosyasını yükler\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            logger.info(f\"{len(data)} tez verisi yüklendi\")\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"JSON dosyası yüklenirken hata oluştu: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    # Neo4j bağlantı bilgileri\n",
    "    neo4j_uri = \"bolt://localhost:7687\"\n",
    "    neo4j_user = \"neo4j\"\n",
    "    neo4j_password = \"12345678\"\n",
    "    \n",
    "    # JSON dosya yolu\n",
    "    json_file_path = \"/home/serdar/Documents/structural-analysis-of-distance-education-theses-via-knowledge-graphs/data/thesis_results-final/thesis_results.json\"  # JSON dosyanızın yolu\n",
    "    \n",
    "    # JSON verisini yükle\n",
    "    data = load_json_data(json_file_path)\n",
    "    \n",
    "    if not data:\n",
    "        logger.error(\"Veri yüklenemedi, işlem sonlandırılıyor\")\n",
    "        return\n",
    "    \n",
    "    # Neo4j bağlantısı\n",
    "    importer = Neo4jImporter(neo4j_uri, neo4j_user, neo4j_password)\n",
    "    \n",
    "    try:\n",
    "        # Veritabanını temizle\n",
    "        importer.clear_database()\n",
    "        \n",
    "        # Constraint'leri oluştur\n",
    "        importer.create_constraints()\n",
    "        \n",
    "        # Verileri aktar (optimize edilmiş metot)\n",
    "        importer.bulk_import_optimized(data)\n",
    "        \n",
    "        logger.info(\"Veri aktarımı başarıyla tamamlandı\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Veri aktarımı sırasında hata oluştu: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        importer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
