{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23659b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "# Initialize the OpenAI API client\n",
    "client = OpenAI()  # API anahtarınızı ortam değişkeninden alın\n",
    "\n",
    "# Define custom exception for rate limiting\n",
    "class RateLimitException(Exception):\n",
    "    pass\n",
    "\n",
    "# Veri yükleme/kaydetme işlemleri için yardımcı fonksiyonlar\n",
    "def load_progress():\n",
    "    \"\"\"Load existing progress and entity database from files.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(\"processing_progress.json\"):\n",
    "            with open(\"processing_progress.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                progress = json.load(f)\n",
    "                print(f\"Loaded progress: Processed {progress['processed_count']} theses\")\n",
    "                return progress\n",
    "        return {\n",
    "            \"processed_count\": 0,\n",
    "            \"last_processed_index\": -1,\n",
    "            \"failed_indices\": []\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading progress: {e}\")\n",
    "        return {\n",
    "            \"processed_count\": 0,\n",
    "            \"last_processed_index\": -1,\n",
    "            \"failed_indices\": []\n",
    "        }\n",
    "\n",
    "def load_entity_database():\n",
    "    \"\"\"Load existing entity database if available.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(\"entity_database.json\"):\n",
    "            with open(\"entity_database.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                database = json.load(f)\n",
    "                entity_count = sum(len(entities) for entities in database.values())\n",
    "                print(f\"Loaded entity database with {entity_count} entities\")\n",
    "                return database\n",
    "        return {\n",
    "            \"STAKEHOLDER\": [],\n",
    "            \"PROBLEM_CHALLENGE\": [],\n",
    "            \"SOLUTION_APPROACH\": [],\n",
    "            \"FOCUS_AREA_THEME\": []\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading entity database: {e}\")\n",
    "        return {\n",
    "            \"STAKEHOLDER\": [],\n",
    "            \"PROBLEM_CHALLENGE\": [],\n",
    "            \"SOLUTION_APPROACH\": [],\n",
    "            \"FOCUS_AREA_THEME\": []\n",
    "        }\n",
    "\n",
    "def save_progress(progress):\n",
    "    \"\"\"Save current processing progress.\"\"\"\n",
    "    with open(\"processing_progress.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(progress, f, indent=2)\n",
    "\n",
    "def save_entity_database(database):\n",
    "    \"\"\"Save current entity database.\"\"\"\n",
    "    with open(\"entity_database.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(database, f, indent=2)\n",
    "\n",
    "def save_results(results):\n",
    "    \"\"\"Save processed thesis results.\"\"\"\n",
    "    with open(\"thesis_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "def get_system_prompt(existing_entities_json):\n",
    "    \"\"\"Generate the system prompt with the current entity database.\"\"\"\n",
    "    return f\"\"\"You are a specialized academic text analyzer who focuses on extracting entities and their relationships from distance education thesis abstracts. Your task is to extract four types of entities (stakeholders, problems/challenges, solutions/approaches, and focus areas/themes) and their relationships.\n",
    "\n",
    "EXISTING ENTITIES DATABASE:\n",
    "{json.dumps(existing_entities_json, indent=2)}\n",
    "\n",
    "ENTITY EXTRACTION RULES:\n",
    "1. STAKEHOLDER:\n",
    "   - Extract people, groups, or institutions involved in or affected by distance education\n",
    "   - Examples: student, teacher, researcher, university, school administrator, educational institution\n",
    "   - Always use singular form and standardized terms (e.g., \"student\" not \"students\")\n",
    "   - Balance specificity with generality - use specific terms (e.g., \"physics teacher\") only when the specialty is important to the context\n",
    "   - Educational institutions should be extracted with their specific names when available (e.g., \"National Defense University\" rather than generic \"university\")\n",
    "   - Include \"thesis\" itself as a STAKEHOLDER to enable proper EXAMINES relationships\n",
    "   - FIRST CHECK if the stakeholder already exists in the database and USE THE EXISTING ENTITY NAME for consistency\n",
    "   \n",
    "2. PROBLEM_CHALLENGE:\n",
    "   - Extract issues, barriers, difficulties, or challenges mentioned in distance education\n",
    "   - Examples: internet access issue, student motivation problem, assessment difficulty, lack of interaction\n",
    "   - Include both technical problems (infrastructure) and pedagogical challenges (engagement)\n",
    "   - Use descriptive phrases that identify both the problem area and its specific manifestation (e.g., \"low technological pedagogical content knowledge\" rather than just \"knowledge gap\")\n",
    "   - Focus on core problems, not symptoms\n",
    "   - FIRST CHECK if the problem/challenge already exists in the database and USE THE EXISTING ENTITY NAME for consistency\n",
    "   \n",
    "3. SOLUTION_APPROACH:\n",
    "   - Extract methods, strategies, models, frameworks, implementations, or technologies that address challenges\n",
    "   - Examples: hybrid education model, in-service training, cooperative learning, flipped classroom, learning management system, video conferencing tool\n",
    "   - Include both pedagogical approaches, technological tools, and organizational/administrative solutions\n",
    "   - Technologies should be specific when possible (e.g., \"learning management system\" rather than general \"technology\")\n",
    "   - Include data collection tools when they are significant to the solution (e.g., \"mobile learning application\", \"student assessment platform\")\n",
    "   - Do not include research methodologies (statistical analysis, content analysis, etc.) in this category\n",
    "   - Do not classify \"distance education\" itself as a solution approach, it should be a FOCUS_AREA_THEME\n",
    "   - FIRST CHECK if the solution/approach already exists in the database and USE THE EXISTING ENTITY NAME for consistency\n",
    "   \n",
    "4. FOCUS_AREA_THEME:\n",
    "   - Extract main research areas, contexts, or themes that the thesis examines\n",
    "   - Examples: digital competency, teacher attitudes, student motivation, academic achievement\n",
    "   - \"Distance education\" itself should typically be classified as a FOCUS_AREA_THEME, not a solution\n",
    "   - When \"technology integration\" is mentioned, prefer the more specific term \"technology integration in education\" for clarity\n",
    "   - Use a granular approach for educational contexts (e.g., \"science education\" rather than just \"education\")\n",
    "   - Always identify at least one primary focus area for each thesis\n",
    "   - Include educational levels (higher education, K-12) and subject domains when relevant\n",
    "   - FIRST CHECK if the focus area/theme already exists in the database and USE THE EXISTING ENTITY NAME for consistency\n",
    "\n",
    "RELATIONSHIP RULES:\n",
    "1. USES:\n",
    "   - Use when a stakeholder employs a solution/approach\n",
    "   - Example: \"faculty member\" USES \"learning management system\"\n",
    "   - Example: \"classroom teacher\" USES \"video support\"\n",
    "   - This relationship typically connects STAKEHOLDER with SOLUTION_APPROACH\n",
    "   - Note: All technological tools and platforms are now classified under SOLUTION_APPROACH\n",
    "\n",
    "2. FACES:\n",
    "   - Use when a stakeholder encounters a problem or challenge\n",
    "   - Example: \"UZEM manager\" FACES \"systemic problems\"\n",
    "   - Example: \"student\" FACES \"transportation problem\"\n",
    "   - This relationship typically connects STAKEHOLDER with PROBLEM_CHALLENGE\n",
    "\n",
    "3. REQUIRES:\n",
    "   - Use when one entity necessitates another entity\n",
    "   - Example: \"distance education\" REQUIRES \"learning management system\"\n",
    "   - Example: \"hybrid education system\" REQUIRES \"new generation learning technologies\"\n",
    "   - This relationship can connect various entity types where one depends on the other\n",
    "   - Especially useful for connecting FOCUS_AREA_THEME with necessary SOLUTION_APPROACH entities\n",
    "\n",
    "4. ADDRESSES:\n",
    "   - Use when a solution targets a specific problem or when a focus area aims at a stakeholder\n",
    "   - Example: \"in-service training program\" ADDRESSES \"digital competency gap\"\n",
    "   - Example: \"learning management system\" ADDRESSES \"lack of interaction\"\n",
    "   - This relationship typically connects SOLUTION_APPROACH with PROBLEM_CHALLENGE\n",
    "   - When a technological solution addresses a problem, always create this relationship\n",
    "\n",
    "5. ENHANCES:\n",
    "   - Use when one entity positively affects another entity\n",
    "   - Example: \"technology integration in education\" ENHANCES \"course permanence\"\n",
    "   - Example: \"video support\" ENHANCES \"student interest\"\n",
    "   - This relationship indicates positive impact between various entity types\n",
    "   - Can connect SOLUTION_APPROACH with FOCUS_AREA_THEME or with STAKEHOLDER\n",
    "\n",
    "6. HINDERS:\n",
    "   - Use when one entity negatively affects another entity\n",
    "   - Example: \"technological inadequacy\" HINDERS \"distance education quality\"\n",
    "   - Example: \"lack of parent support\" HINDERS \"student success\"\n",
    "   - This relationship indicates negative impact between various entity types\n",
    "\n",
    "7. EXAMINES:\n",
    "   - Use when a thesis or research investigates a specific topic or area\n",
    "   - Example: \"thesis\" EXAMINES \"digital competency levels\"\n",
    "   - Example: \"research\" EXAMINES \"distance education management\"\n",
    "   - ALWAYS create at least one EXAMINES relationship for each thesis\n",
    "   - This relationship typically connects \"thesis\" (which should be extracted as a STAKEHOLDER) with the main FOCUS_AREA_THEME\n",
    "\n",
    "# SPECIFIC GUIDELINES\n",
    "\n",
    "1. Extract each unique entity only once in its standardized form\n",
    "2. All entities should be in English, singular form, and lowercase format (except for proper nouns)\n",
    "3. Entity names should be concise but descriptive (2-5 words recommended)\n",
    "4. Each relationship must use entities from your extracted list\n",
    "5. For each entity category, extract 1-7 items depending on thesis content and complexity\n",
    "6. Create at least 5 meaningful relationships that are explicitly stated or strongly implied in the text\n",
    "7. Prioritize explicitly stated relationships; avoid speculation or reaching conclusions not supported by the text\n",
    "8. ALWAYS check if an entity already exists in the database before creating a new one\n",
    "9. When you find a match or similar concept in the existing database, USE THAT ENTITY NAME rather than creating a variant\n",
    "10. Only create new entities when you are confident no suitable match exists in the database\n",
    "11. For each thesis, ALWAYS create at least one EXAMINES relationship to capture the main research focus\n",
    "12. Maintain categorical consistency: the same entity should not appear in multiple categories (e.g., \"distance education\" should be consistently classified as FOCUS_AREA_THEME)\n",
    "13. Research methodologies (statistical analysis, content analysis, descriptive analysis) should NOT be extracted as entities in any category\n",
    "14. Standardize similar entities: use consistent naming for similar concepts (e.g., choose either \"teacher\" or \"instructor\" consistently)\n",
    "15. Use only the seven defined relationship types and maintain consistent directionality:\n",
    "    - USES: stakeholder → solution/approach they employ\n",
    "    - FACES: stakeholder → problem/challenge they encounter\n",
    "    - ADDRESSES: solution/approach → problem/challenge it solves\n",
    "    - ENHANCES: entity → entity it improves or strengthens\n",
    "    - REQUIRES: entity → entity it needs to function effectively\n",
    "    - HINDERS: entity → entity it impedes or negatively affects\n",
    "    - EXAMINES: thesis → focus area/theme being researched\n",
    "16. All technological tools, platforms, and educational technologies should be classified under SOLUTION_APPROACH when they are presented as solutions to educational challenges\n",
    "17. Ensure that each technological solution classified under SOLUTION_APPROACH has at least one meaningful relationship showing either who USES it, what problem it ADDRESSES, or what it ENHANCES\n",
    "18. Use descriptive phrases for problems that identify both the problem area and its specific manifestation (e.g., \"low technological pedagogical content knowledge\" rather than just \"knowledge gap\")\n",
    "19. For educational institutions, extract with their specific names when available (e.g., \"National Defense University\" rather than just \"university\")\n",
    "20. Always include \"thesis\" as a STAKEHOLDER to enable proper EXAMINES relationships\n",
    "21. Aim for a balanced distribution of relationship types when the content supports it\n",
    "22. Use ENHANCES only when clear positive impact is stated in the text\n",
    "23. Use REQUIRES only when one entity is clearly dependent on another\n",
    "24. Consider including HINDERS relationships when obstacles, barriers, or negative effects are mentioned\n",
    "\n",
    "JSON output:\n",
    "{{\n",
    "  \"thesis_id\": \"<string>\",\n",
    "  \"year\": \"<string|number>\",\n",
    "  \"entities\": {{\n",
    "    \"STAKEHOLDER\": [\n",
    "      \"<ENTITY_NAME_1>\",\n",
    "      \"<ENTITY_NAME_2>\"\n",
    "    ],\n",
    "    \"PROBLEM_CHALLENGE\": [\n",
    "      // ...\n",
    "    ],\n",
    "    \"SOLUTION_APPROACH\": [\n",
    "      // ...\n",
    "    ],\n",
    "    \"FOCUS_AREA_THEME\": [\n",
    "      // ...\n",
    "    ]\n",
    "  }},\n",
    "  \"relations\": [\n",
    "    {{\n",
    "      \"source\": \"<ENTITY_NAME>\",\n",
    "      \"target\": \"<ENTITY_NAME>\",\n",
    "      \"relation\": \"<RELATION_TYPE>\"\n",
    "    }}\n",
    "    // Relation objects...\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def parse_json_from_response(response_text):\n",
    "    \"\"\"Extract JSON from the response text, handling different formats.\"\"\"\n",
    "    # Try to parse directly first\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # Try to extract JSON from markdown code blocks\n",
    "        if \"```json\" in response_text:\n",
    "            json_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "            return json.loads(json_text)\n",
    "        elif \"```\" in response_text:\n",
    "            json_text = response_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "            return json.loads(json_text)\n",
    "        else:\n",
    "            # Try to find JSON-like structure\n",
    "            start_idx = response_text.find(\"{\")\n",
    "            end_idx = response_text.rfind(\"}\") + 1\n",
    "            if start_idx >= 0 and end_idx > 0:\n",
    "                json_text = response_text[start_idx:end_idx]\n",
    "                return json.loads(json_text)\n",
    "            raise ValueError(\"Could not extract JSON from response\")\n",
    "\n",
    "@retry(\n",
    "    retry=retry_if_exception_type(RateLimitException),\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "    reraise=True\n",
    ")\n",
    "def generate_entities_with_retry(input_data, existing_entities_json):\n",
    "    \"\"\"Generate entities from the input data using the OpenAI model with retry logic.\"\"\"\n",
    "    try:\n",
    "        # Get the current system prompt with updated entity database\n",
    "        system_prompt = get_system_prompt(existing_entities_json)\n",
    "        \n",
    "        # Format the input data for GPT\n",
    "        thesis_text = f\"\"\"\n",
    "        Thesis ID: {input_data['thesis_id']}\n",
    "        Year: {input_data['year']}\n",
    "        Title: {input_data['title']}\n",
    "        Abstract: {input_data['abstract']}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate content using the OpenAI model\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",  # GPT-4o modeli kullanıyoruz (GPT-4 Omni)\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": thesis_text}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            max_tokens=8192,\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        result = parse_json_from_response(response.choices[0].message.content)\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e).lower()\n",
    "        # Check if it's a rate limit error\n",
    "        if \"rate limit\" in error_msg or \"quota\" in error_msg or \"too many requests\" in error_msg:\n",
    "            print(f\"Rate limit exceeded. Retrying after backoff: {e}\")\n",
    "            raise RateLimitException(f\"Rate limit error: {e}\")\n",
    "        else:\n",
    "            print(f\"Error generating content: {e}\")\n",
    "            raise\n",
    "\n",
    "def update_entity_database(result, existing_entities_json):\n",
    "    \"\"\"Update the existing entity database with new entities from the result.\"\"\"\n",
    "    if not result or \"entities\" not in result:\n",
    "        print(\"No valid entities found in result\")\n",
    "        return existing_entities_json\n",
    "    \n",
    "    try:\n",
    "        entities = result['entities']\n",
    "        \n",
    "        # Extract entities from each category\n",
    "        for category in [\"STAKEHOLDER\", \"PROBLEM_CHALLENGE\", \"SOLUTION_APPROACH\", \"FOCUS_AREA_THEME\"]:\n",
    "            # Get new entities\n",
    "            new_entities = entities.get(category, [])\n",
    "            \n",
    "            # Add new entities to existing ones (maintaining uniqueness)\n",
    "            existing_entities_json[category] = list(set(existing_entities_json.get(category, []) + new_entities))\n",
    "        \n",
    "        return existing_entities_json\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating entity database: {e}\")\n",
    "        return existing_entities_json\n",
    "\n",
    "def process_thesis(thesis_data, existing_entities_json):\n",
    "    \"\"\"Process a single thesis and update the entity database.\"\"\"\n",
    "    try:\n",
    "        # Format the thesis data for processing\n",
    "        input_data = {\n",
    "            \"thesis_id\": str(thesis_data.get(\"tez_no\", \"\")),\n",
    "            \"year\": thesis_data.get(\"year\", \"\"),\n",
    "            \"title\": thesis_data.get(\"en_title\", \"\"),\n",
    "            \"abstract\": thesis_data.get(\"abstract_en\", \"\")\n",
    "        }\n",
    "        \n",
    "        # Generate entities from the thesis data\n",
    "        result = generate_entities_with_retry(input_data, existing_entities_json)\n",
    "        \n",
    "        if result is None:\n",
    "            print(f\"Failed to process thesis ID: {input_data['thesis_id']}\")\n",
    "            return existing_entities_json, None\n",
    "        \n",
    "        # Add thesis_id and year to the result\n",
    "        result[\"thesis_id\"] = input_data[\"thesis_id\"]\n",
    "        result[\"year\"] = input_data[\"year\"]\n",
    "        \n",
    "        # Update the entity database\n",
    "        updated_entities_json = update_entity_database(result, existing_entities_json)\n",
    "        \n",
    "        return updated_entities_json, result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing thesis: {e}\")\n",
    "        return existing_entities_json, None\n",
    "\n",
    "def process_dataframe(df, start_from_index=0, batch_size=None, retry_failed=True):\n",
    "    \"\"\"Process theses from a pandas DataFrame sequentially.\"\"\"\n",
    "    # Load existing progress and data\n",
    "    progress = load_progress()\n",
    "    entity_database = load_entity_database()\n",
    "    \n",
    "    # Load existing results if available\n",
    "    all_results = []\n",
    "    if os.path.exists(\"thesis_results.json\"):\n",
    "        try:\n",
    "            with open(\"thesis_results.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                all_results = json.load(f)\n",
    "                print(f\"Loaded {len(all_results)} previous results\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading previous results: {e}\")\n",
    "    \n",
    "    # Determine starting index - use the highest of provided index, saved index\n",
    "    start_index = max(start_from_index, progress[\"last_processed_index\"] + 1)\n",
    "    \n",
    "    # If we have failed indices and retry_failed is True, process failed ones first\n",
    "    failed_indices = progress.get(\"failed_indices\", [])\n",
    "    if failed_indices and retry_failed:\n",
    "        print(f\"Processing {len(failed_indices)} previously failed theses first\")\n",
    "        for idx in failed_indices[:]:  # Create a copy to iterate over while modifying\n",
    "            if idx < len(df):\n",
    "                thesis = df.iloc[idx].to_dict()\n",
    "                thesis_id = str(thesis.get('tez_no', 'unknown'))\n",
    "                print(f\"Retrying thesis ID: {thesis_id} (index {idx})\")\n",
    "                \n",
    "                try:\n",
    "                    # Process the thesis with the CURRENT entity database\n",
    "                    entity_database, result = process_thesis(thesis, entity_database)\n",
    "                    \n",
    "                    if result:\n",
    "                        # Add or update result in all_results\n",
    "                        result_idx = next((i for i, r in enumerate(all_results) \n",
    "                                        if r.get('thesis_id') == thesis_id), None)\n",
    "                        if result_idx is not None:\n",
    "                            all_results[result_idx] = result\n",
    "                        else:\n",
    "                            all_results.append(result)\n",
    "                        \n",
    "                        # Remove from failed indices\n",
    "                        failed_indices.remove(idx)\n",
    "                        \n",
    "                        # Update progress\n",
    "                        progress[\"processed_count\"] += 1\n",
    "                    \n",
    "                    # Save progress after each thesis\n",
    "                    progress[\"failed_indices\"] = failed_indices\n",
    "                    save_progress(progress)\n",
    "                    save_entity_database(entity_database)\n",
    "                    save_results(all_results)\n",
    "                    \n",
    "                    # Add a small delay to avoid hitting rate limits\n",
    "                    time.sleep(0.5)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error retrying thesis at index {idx}: {e}\")\n",
    "    \n",
    "    # Process the main batch\n",
    "    print(f\"Starting thesis processing from index {start_index}\")\n",
    "    \n",
    "    # Determine end index\n",
    "    end_index = len(df)\n",
    "    if batch_size:\n",
    "        end_index = min(start_index + batch_size, len(df))\n",
    "    \n",
    "    # Process each thesis in the range sequentially\n",
    "    for i in range(start_index, end_index):\n",
    "        thesis = df.iloc[i].to_dict()\n",
    "        thesis_id = str(thesis.get('tez_no', 'unknown'))\n",
    "        \n",
    "        # Check if this thesis was already processed\n",
    "        if any(r.get('thesis_id') == thesis_id for r in all_results):\n",
    "            print(f\"Skipping already processed thesis ID: {thesis_id} (index {i})\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing thesis ID: {thesis_id} (index {i}, {i-start_index+1}/{end_index-start_index})\")\n",
    "        \n",
    "        try:\n",
    "            # Process the thesis with the CURRENT entity database\n",
    "            entity_database, result = process_thesis(thesis, entity_database)\n",
    "            \n",
    "            if result:\n",
    "                # Add or update result in all_results\n",
    "                result_idx = next((i for i, r in enumerate(all_results) \n",
    "                                if r.get('thesis_id') == thesis_id), None)\n",
    "                if result_idx is not None:\n",
    "                    all_results[result_idx] = result\n",
    "                else:\n",
    "                    all_results.append(result)\n",
    "                \n",
    "                # Update progress\n",
    "                progress[\"processed_count\"] += 1\n",
    "            else:\n",
    "                # Add to failed indices\n",
    "                if i not in failed_indices:\n",
    "                    failed_indices.append(i)\n",
    "            \n",
    "            # Update and save progress\n",
    "            progress[\"last_processed_index\"] = i\n",
    "            progress[\"failed_indices\"] = failed_indices\n",
    "            save_progress(progress)\n",
    "            save_entity_database(entity_database)\n",
    "            save_results(all_results)\n",
    "            \n",
    "            # Add a small delay to avoid hitting rate limits\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing thesis at index {i}: {e}\")\n",
    "            # Add to failed indices\n",
    "            if i not in failed_indices:\n",
    "                failed_indices.append(i)\n",
    "            progress[\"failed_indices\"] = failed_indices\n",
    "            save_progress(progress)\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "    return entity_database, all_results\n",
    "\n",
    "# # Programı çalıştırma\n",
    "# def main():\n",
    "#     # DataFrame'i yükle\n",
    "#     df = pd.read_csv(\"thesis_data.csv\")  # Dosya yolunu doğru şekilde ayarlayın\n",
    "    \n",
    "#     # İşlemeyi başlat\n",
    "#     process_dataframe(df, start_from_index=0, batch_size=None, retry_failed=True)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d78df9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(703, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/mnt/depo/YüksekLisans/dönem-projesi/cleaned-data/uzaktan-eğitim-cleaned_english.csv')\n",
    "df = data.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a18119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 703 entries, 0 to 702\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   tez_no       703 non-null    int64 \n",
      " 1   year         703 non-null    int64 \n",
      " 2   university   703 non-null    object\n",
      " 3   abstract_en  703 non-null    object\n",
      " 4   en_title     701 non-null    object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 27.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbe9bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tez_no</th>\n",
       "      <th>year</th>\n",
       "      <th>university</th>\n",
       "      <th>abstract_en</th>\n",
       "      <th>en_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>782422</td>\n",
       "      <td>2023</td>\n",
       "      <td>Milli Savunma Üniversitesi</td>\n",
       "      <td>The hybrid system has become a necessity of to...</td>\n",
       "      <td>Classroom model designed with new generation l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>821224</td>\n",
       "      <td>2023</td>\n",
       "      <td>Muğla Sıtkı Koçman Üniversitesi</td>\n",
       "      <td>The main purpose of this study is to evaluate ...</td>\n",
       "      <td>Evaluation of the digital competence levels of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>739239</td>\n",
       "      <td>2022</td>\n",
       "      <td>Kırşehir Ahi Evran Üniversitesi</td>\n",
       "      <td>This research aims to determine the level of t...</td>\n",
       "      <td>Determination of classroom teacher\\'s technolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>724056</td>\n",
       "      <td>2022</td>\n",
       "      <td>Sakarya Üniversitesi</td>\n",
       "      <td>In this research, it is aimed to specify the p...</td>\n",
       "      <td>The problems and solution strategies encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>722422</td>\n",
       "      <td>2022</td>\n",
       "      <td>Ondokuz Mayıs Üniversitesi</td>\n",
       "      <td>If you want to take special talented individua...</td>\n",
       "      <td>Evaluation of distance education applications ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tez_no  year                       university  \\\n",
       "0  782422  2023       Milli Savunma Üniversitesi   \n",
       "1  821224  2023  Muğla Sıtkı Koçman Üniversitesi   \n",
       "2  739239  2022  Kırşehir Ahi Evran Üniversitesi   \n",
       "3  724056  2022             Sakarya Üniversitesi   \n",
       "4  722422  2022       Ondokuz Mayıs Üniversitesi   \n",
       "\n",
       "                                         abstract_en  \\\n",
       "0  The hybrid system has become a necessity of to...   \n",
       "1  The main purpose of this study is to evaluate ...   \n",
       "2  This research aims to determine the level of t...   \n",
       "3  In this research, it is aimed to specify the p...   \n",
       "4  If you want to take special talented individua...   \n",
       "\n",
       "                                            en_title  \n",
       "0  Classroom model designed with new generation l...  \n",
       "1  Evaluation of the digital competence levels of...  \n",
       "2  Determination of classroom teacher\\'s technolo...  \n",
       "3  The problems and solution strategies encounter...  \n",
       "4  Evaluation of distance education applications ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1db77f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded progress: Processed 700 theses\n",
      "Error loading entity database: Expecting value: line 1 column 1 (char 0)\n",
      "Loaded 700 previous results\n",
      "Processing 3 previously failed theses first\n",
      "Retrying thesis ID: 117810 (index 695)\n",
      "Retrying thesis ID: 100177 (index 696)\n",
      "Retrying thesis ID: 117774 (index 697)\n",
      "Starting thesis processing from index 703\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Programı çalıştırma\n",
    "def main():\n",
    "    # DataFrame'i yükle\n",
    "    # df = pd.read_csv(\"thesis_data.csv\")  # Dosya yolunu doğru şekilde ayarlayın\n",
    "    \n",
    "    # İşlemeyi başlat\n",
    "    process_dataframe(df, start_from_index=0, batch_size=None, retry_failed=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88615d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The purpose of this study is to compare the academic success of Open High School (OHS) - Professional Open Teaching Program (POTP) students and Girl Vocational High School (GVHS) students. The population of this study, during 1999-2000 education semester second term, consisted of the students of clothing department in Ziibeyde Hanım Girl Vocational School and the students of OHS-POTP. All (25) POTP students, 36 students chosen from GVHS were included randomly in this study. In the study, \"The Information Summative Test\" which is used for measuring the level of cognitive behaviours of the students, was prepared as to the purposes of GVHS Educational Programs. It was obtained the validity and the reliability of the work by testing. It was asked 55 for the first class, 70 for the second class, 80 questions for the third class. The test was done as a pre-test at the beginning of the term and as a post-test at the end of the term. Counting the pre_post-tests scores of the students, it was got the datums that is use for comparing the successes of the students at the subject of cognitive behaviours. It was done \"Product Evaluation Scales\" and \"Process Evaluation Scales\" to measure psychomotor behaviours of the students. It was determined the first products that the students will make during the term. So, the products were determined as to blouse for the first class students, jacket and dress for the second class ones, and trousers for the third class students according to the special features of the works, the scores were determined on to 100 (scores) then, evaluating according to between 2-13 scores, \"Product Evaluation Scales\" were prepared and \"Process Evaluation Scales\", as to scores of each kind of task, were prepared as distributing work steps, \"The Information Summative Test\", \"Product Evaluation Scales\" and \"Process Evaluation Scales\" were proceeded by the researcher, making good use of sources and asking for the points of view of the specialists. And,208 according to these scales psychomotor behaviours of the students at the sampling, during the term, at weekly lessons times, were evaluated by an evaluation group consisted of a researcher, a specialist and a class teacher. In the research the comparison between the cognitive and motor success of the students were made with the t-test between independent groups. The relation between the cognitive and motor success of the students were made with the correlation test. The levels of the significancy were taken as 0.05 and 0.001. According to the data and interpretation; * In cognitive behaviour of the students; - In first class, there is a significant difference between pre-tests scores of the POTP students and GVHS students, in favour of the POTP students In cognitive behaviour. In second and third class, there is no significant difference between pre-tests scores of the POTP students and GVHS students. - There is a significant difference between post-tests scores of the POTP students and GVHS students, in favour of the GVHS students in second class In cognitive behaviour, but the POTP students in first and third class. - There is no significant difference between pre-test and post-test scores of the POTP students In cognitive behaviour. - There is a significant difference between pre-test and post-test scores of the GVHS students, in favour of the post-test In cognitive behaviour.209 * In psychomotor behaviours of the students; - There is a significant difference between motor behaviours scores of the POTP and GVHS students in favour of the POTP students in the first and third classes In psychomotor behaviours. In the second class there is no significant difference between pre-tests scores of the POTP students and GVHS students. * In cognitive and psychomotor behaviour of the students; - In the third class, there is a significant relation between cognitive behaviour and motor behaviour scores of the POTP students. In the first and second classes, there is no significant relation between cognitive behaviour and motor behaviour scores of the POTP students. - In the second class second prodact and third class, there is a significant relation between cognitive behaviour and motor behaviour scores of the GVHS students. In the first and second classes firs prodact, there is no significant relation between cognitive behaviour and motor behaviour scores of the GVHS students. As a result, there is no significant difference between POTP students and GVHS students In cognitive behaviour. POTP students has been found to be more successful than GVHS students in psychomotor behaviours.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[695].abstract_en"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
